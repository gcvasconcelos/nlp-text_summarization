{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MT - Text Sumarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFuoD0bVYN64pLW62DtxyR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcvasconcelos/text_summarization/blob/main/text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZghk0_qLL6Y"
      },
      "source": [
        "# Sumarização automática abstrativa\n",
        "\n",
        "Neste projeto, é proposta a aplicação de um modelo *sequence-to-sequence* usando Redes Neurais Recorrentes (RNN) implementados em uma arquitetura *encoder-decoder* com o objetivo da resolução da tarefa de sumarização automática abstrativa, ou seja, a construção de um resumo que capture o sentido e contexto presente no texto original mas que não utiliza necessariamente as palavras deste. \n",
        "\n",
        "Os textos estão escritos na língua portuguesa e são transcrições de pronunciamentos realizados por senadores no Senado Federal do Brasil. A base têm a característica especial de possuir um extenso vocabulário e tamanho onde, todavia, cada discurso discorre sobre pouco mais de um assunto geral. \n",
        "\n",
        "Para lidar com esses desafios, na fase de treinamento do modelo foi utilizado no *encoder* um conjunto de modelos *Long Short-Term Memory* (LSTM) bi-direcional que é treinado com os textos dos discursos e tem como fim capturar seu contexto, tanto do passado como do futuro. Partes importantes deste contexto são selecionadas por um mecanismo de *attention* que é utilizado para inicializar o *decoder*, uma outra LSTM que é treinada com resumos gerados por humanos. \n",
        "\n",
        "Os resumos foram gerados automaticamente para 14.535 discursos e avaliados a partir das métricas ROUGE e BERTScore, que tiveram um resultado satisfatório quando comparados com a literatura.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atK5b39KLVgr"
      },
      "source": [
        "## Configuração do Ambiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIm485qMTiA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee24dd1-5bdf-42f0-f30d-369ec213ee86"
      },
      "source": [
        "!pip install unidecode\n",
        "!pip install rouge\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "print(f\"GPU is available for torch: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU is available for tensorflow: {tf.test.gpu_device_name()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "GPU is available for torch: True\n",
            "GPU is available for tensorflow: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB_BL5_3Peds",
        "outputId": "1a107723-e2f9-43c6-b289-6691cf549fc5"
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install -U spacy-lookups-data\n",
        "!python -m spacy download pt_core_news_lg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.3.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.5)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already up-to-date: spacy-lookups-data in /usr/local/lib/python3.6/dist-packages (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy-lookups-data) (50.3.2)\n",
            "Requirement already satisfied: pt_core_news_lg==2.3.0 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-2.3.0/pt_core_news_lg-2.3.0.tar.gz#egg=pt_core_news_lg==2.3.0 in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_lg==2.3.0) (2.3.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (7.4.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (0.8.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.1.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (50.3.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->pt_core_news_lg==2.3.0) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zXguWKXTuBM"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "import spacy\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional, Add\n",
        "# from attention import Attention\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "from rouge import Rouge\n",
        "from bert_score import score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzSSM2TLhU-R",
        "outputId": "84a2dc40-14ac-4e39-f9ab-514c8667ea43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            " discursos_clean.csv\t   'MT - Text Sumarization.ipynb'   word2vec_new.model\n",
            " discursos_raw_all.pickle   val_data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3_YrBzRSbW3"
      },
      "source": [
        "## Pré processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "isfbXKwTV7pI",
        "outputId": "56ca2af0-b296-4ce8-ca33-ca557ab86af1"
      },
      "source": [
        "data_raw = pickle.load(open(\"/content/drive/My Drive/Colab Notebooks/discursos_raw_all.pickle\", \"rb\"))\n",
        "raw_df = pd.DataFrame(data_raw)\n",
        "raw_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IdentificacaoParlamentar</th>\n",
              "      <th>IdentificacaoPronunciamento</th>\n",
              "      <th>Conteudo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'CodigoParlamentar': '825', 'CodigoPublicoNaL...</td>\n",
              "      <td>{'CodigoPronunciamento': '396425', 'TipoUsoPal...</td>\n",
              "      <td>O SR. PAULO PAIM (Bloco/PT - RS. Pronuncia o s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'CodigoParlamentar': '4697', 'NomeParlamentar...</td>\n",
              "      <td>{'CodigoPronunciamento': '400383', 'TipoUsoPal...</td>\n",
              "      <td>A SRª ANGELA PORTELA (Bloco/PT - RR. Pronuncia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'CodigoParlamentar': '4531', 'CodigoPublicoNa...</td>\n",
              "      <td>{'CodigoPronunciamento': '410003', 'TipoUsoPal...</td>\n",
              "      <td>O SR. JAYME CAMPOS (Bloco Minoria/DEM - MT. Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'CodigoParlamentar': '53', 'NomeParlamentar':...</td>\n",
              "      <td>{'CodigoPronunciamento': '386066', 'TipoUsoPal...</td>\n",
              "      <td>SENADO FEDERAL SF -              SECRETARIA-GE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'CodigoParlamentar': '4529', 'NomeParlamentar...</td>\n",
              "      <td>{'CodigoPronunciamento': '399259', 'TipoUsoPal...</td>\n",
              "      <td>O SR. CÍCERO LUCENA  (Bloco/PSDB - PB) - É por...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            IdentificacaoParlamentar  ...                                           Conteudo\n",
              "0  {'CodigoParlamentar': '825', 'CodigoPublicoNaL...  ...  O SR. PAULO PAIM (Bloco/PT - RS. Pronuncia o s...\n",
              "1  {'CodigoParlamentar': '4697', 'NomeParlamentar...  ...  A SRª ANGELA PORTELA (Bloco/PT - RR. Pronuncia...\n",
              "2  {'CodigoParlamentar': '4531', 'CodigoPublicoNa...  ...  O SR. JAYME CAMPOS (Bloco Minoria/DEM - MT. Pr...\n",
              "3  {'CodigoParlamentar': '53', 'NomeParlamentar':...  ...  SENADO FEDERAL SF -              SECRETARIA-GE...\n",
              "4  {'CodigoParlamentar': '4529', 'NomeParlamentar...  ...  O SR. CÍCERO LUCENA  (Bloco/PSDB - PB) - É por...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "GyUtuR_vNZam",
        "outputId": "fca793c6-9d16-433b-c273-a88a5f0e4671"
      },
      "source": [
        "data_df = pd.DataFrame(columns=['speech', 'speech_summary'])\n",
        "data_df['speech'] = raw_df['Conteudo']\n",
        "data_df['speech_summary'] = [dic.get('TextoResumo') for dic in raw_df['IdentificacaoPronunciamento']]\n",
        "\n",
        "data_df.info()\n",
        "data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74981 entries, 0 to 74980\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   speech          74981 non-null  object\n",
            " 1   speech_summary  74167 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>speech_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O SR. PAULO PAIM (Bloco/PT - RS. Pronuncia o s...</td>\n",
              "      <td>\\n      Destaque à aprovação, pelo Senado Fede...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A SRª ANGELA PORTELA (Bloco/PT - RR. Pronuncia...</td>\n",
              "      <td>\\n      Satisfação com a postura do Governo Fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O SR. JAYME CAMPOS (Bloco Minoria/DEM - MT. Pr...</td>\n",
              "      <td>\\n      Apelo no sentido da aprovação, pela Câ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SENADO FEDERAL SF -              SECRETARIA-GE...</td>\n",
              "      <td>\\n      Relato sobre as dificuldades verificad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O SR. CÍCERO LUCENA  (Bloco/PSDB - PB) - É por...</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              speech                                     speech_summary\n",
              "0  O SR. PAULO PAIM (Bloco/PT - RS. Pronuncia o s...  \\n      Destaque à aprovação, pelo Senado Fede...\n",
              "1  A SRª ANGELA PORTELA (Bloco/PT - RR. Pronuncia...  \\n      Satisfação com a postura do Governo Fe...\n",
              "2  O SR. JAYME CAMPOS (Bloco Minoria/DEM - MT. Pr...  \\n      Apelo no sentido da aprovação, pela Câ...\n",
              "3  SENADO FEDERAL SF -              SECRETARIA-GE...  \\n      Relato sobre as dificuldades verificad...\n",
              "4  O SR. CÍCERO LUCENA  (Bloco/PSDB - PB) - É por...                                               None"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J5dmyY3NnQZ"
      },
      "source": [
        "Removendo discursos sem resumos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5cGFgrtNkvQ",
        "outputId": "e5bc1cdf-60e8-46aa-ef87-63d0b4a4d045"
      },
      "source": [
        "data_df = data_df[data_df['speech_summary'].notna()]\n",
        "data_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 74167 entries, 0 to 74980\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   speech          74167 non-null  object\n",
            " 1   speech_summary  74167 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtleSWoqNwXh",
        "outputId": "62957baa-bbb4-465c-eed1-f06494a10b47"
      },
      "source": [
        "contraction_list = {\n",
        "    \"v\\. exa\": \"vossa excelencia\"\n",
        "    ,\"s\\. exa\": \"vossa excelencia\"\n",
        "    , \"sr\\.\": \"senhor\"\n",
        "    , \"srs\\.\": \"senhores\"\n",
        "    , \"sra\\.\": \"senhora\"\n",
        "    , \"sras\\.\": \"senhoras\"\n",
        "    , \"pag\\.\": \"pagina\"\n",
        "    , \"exm\\.\": \"excelentissimo\"\n",
        "    , \"exma\\.\": \"excelentissima\"\n",
        "}\n",
        "\n",
        "def text_cleaning(col_name, is_target=False):\n",
        "    for text in data_df[col_name]:\n",
        "        text = unidecode(text).lower()\n",
        "        for contraction in contraction_list.keys():\n",
        "            text = re.sub(contraction, contraction_list[contraction], text)\n",
        "\n",
        "        text = re.sub(r\"\\\\n|\\\\xa0\", ' ', text) # remove escape characters\n",
        "        text = re.sub(r\"[^a-z]\", ' ', text) # keep only words\n",
        "\n",
        "        if is_target:\n",
        "            text = re.sub(r\"\\b[a-z]{1,2}\\b\", ' ', text) # remove <2 characters\n",
        "\n",
        "        text = re.sub(r\"\\s+\", ' ', text) # remove extra spaces (at the end)\n",
        "        text = text.strip()\n",
        "        yield text\n",
        "\n",
        "cleaned_speech = text_cleaning('speech', is_target=True)\n",
        "cleaned_speech_summary = text_cleaning('speech_summary')\n",
        "\n",
        "nlp = spacy.load('pt_core_news_lg', disable=['tagger', 'parser', 'ner'])\n",
        "\n",
        "def remove_stopwords(doc, is_target=False):\n",
        "    if is_target:\n",
        "        corpus = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    else:\n",
        "        corpus = [token.text for token in doc if not token.is_stop]\n",
        "    return ' '.join(corpus)\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "corpus = [remove_stopwords(doc, is_target=True) for doc in nlp.pipe(cleaned_speech, batch_size=5000, n_threads=-1)]\n",
        "labels = [remove_stopwords(doc) for doc in nlp.pipe(cleaned_speech_summary, batch_size=5000, n_threads=-1)]\n",
        "\n",
        "print(f'Processing time: {round((time.time() - t) / 60, 2)} mins')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing time: 12.53 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFSqVn74Ogsx",
        "outputId": "9b2a0d51-e196-443e-b360-59692e253e57"
      },
      "source": [
        "data_df['speech_clean'] = corpus\n",
        "data_df['speech_summary_clean'] = labels\n",
        "data_df['speech_summary_clean'] = data_df['speech_summary_clean'].apply(lambda summ : '_START_ '+ summ + ' _END_')\n",
        "\n",
        "for i in range(3):\n",
        "    print(\"Speech: \",data_df['speech_clean'][i])\n",
        "    print(\"Summary: \",data_df['speech_summary_clean'][i])\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Speech:  senhor paulo paim bloco pronunciar seguinte discursar revisao orador senador mozarildo cavalcanti presidir sessao senador fernando collor mello usar tribuna orador registro senhor presidente analisar detalhar importancia aprovacao senado camara projeto autista analisar fazer mediante cartar receber principal lider dizer autista pai encaminhar cartar semana sr berenice piana piana registro hoje noite estar hotel sao marcar brasilia participar solenidade posse diretoria contratuh eleito quinquenio dezembro dezembro moacyr roberto tesch atual presidente confederacao ativo participante reeleito presidencia confederacao convidar congresso nacional dezena dezena durante ano dia dezembro confederacao dar brasilia congresso nacional trabalhador turismo hospitalidade dirigente sindicar participar evento objetivo definir bandeiro contratuh defender continuar defender muito delas proximo mandatar confederacao apresentar tambem dia exposicao informativo ultimos ano janeiro dezembro fazer balanco mandatar exposicao mostrar turismo hospitalidade pego hoteleiro naturalmente trabalhar confederacao realizar contratuh completar ultimar dia novembro ano existencia fundacao ano ano entidade lutar projetos nao corporativo categoria tambem interessar nacional trabalhador visto valorizacao trabalhador aposentar pensionista insercao capacitacao trabalhador mercar trabalhar naturalmente turismo hospitalidade contratuh mostrar tambem atento questoes nacional ser parceiro lutar valorizacao beneficios aposentar pensionista lutar fator previdenciario lamentavelmente camara encolher pressao executivo jogar votacao ano lutar igualdade racial lutar fortalecer clt frente nacional defeso trabalhador clt coordenar principalmente ano clt completar ano entao cumprimentar diretoria contratuh pessoa presidente moacyr tesch trabalhar realizar atar merecer cumprimento desejar sucesso caminhar combativo confederacao nacional trabalhador ter trabalhar frente registrar senhor presidente nao nao enaltecer nao fortalecer nao comentar tribuna aprovacao casar tres projetos semana comeco deles aprovacao projeto permitir sucessao familiar servico taxi autoria senador expedito junior relatoria competente senador renan calheiros projeto haver ser aprovar senado outubro acompanhar projeto passar passar encaminhar camara retornar senado substitutivo aprovar unanimidade comissao assunto social relatorio renan calheiros vir entao plenario liderar partir projeto tera considerar justica taxista passar direito enfim formal legal deles citar novamente começar movimentar projeto cercar ano receber cartar taxista portar alegrar dizer trabalhar taxi pai filhar pai morrer concessao nao ficar familia familia ficar pai fonte recurso sustentacao filhar ficar desempregar cartar mexer dizer coracao almo mentir dedicar exaustivamente projeto ser aprovar agradeco numerar mail correspondencias receber brasil cumprimentar naturalmente senador expedito junior senador renan calheiros relator senador excelencia senador mozarildo cavalcanti ajudar aprovacao projeto sucessao justo ficar feliz proposto aprovar esperar sera sancionar cumprimento taxista brasil lei passar legalizar patrimonio patrimonio instrumentar trabalhar normalmente passar pai filhar alguem titular entender dever passar outro temer nao deixar comentar plc executivo criar cargo defensor publicar uniao variar vir tribuna defender categoria fazer inumeras audiencias publicar defender criacao vago numerar defensor publicos insuficiente atender demandar defensor publicar defender pobre tinhamos numerar insignificante defensor publicos brasil inumeras audiencias publicar muito mobilizacao enfim projeto chegar casar aprovar casar unanimidade cargo ser efetivados pessoa carente agradecer sao necessitar pai bater palmar precisar contar devido orientacao juridica trabalhar defensor publicar parabens defensor publicos senador mozarildo excelencia acompanhar debater hoje realidade reunir inumeras comissao direito humano excelencia comissao assunto social excelencia excelencia participar sentir jovem jovem querer exercer profissao ser concursados passar defender enfim apelar deles ouvir hoje poder ano estarao colocar pai defender gente senador mozarildo pronunciamento fundir autista excelencia participar tambem citar excelencia nao presidencia excelencia membro ativo comissao direito humano comissao assunto social excelencia acompanhar processar muito cartar autista pedir haver politicar nacional autista cartar receber principalmente sr berenice piana piana claro mexer comigo trazer plenario levar comissao direito humano levar comissao assunto social enfim projeto surgir construido frutar proprios autista familiar entrar projeto emendar popular dizer comissao direito humano legislacao participativo permitir autista entrar proposto acatar proposto comissao direito humano passar tramitar casar hoje realidade gracas deus passar ler cartar sao liderar comecou lutar senado conosco hoje projeto aprovar mao presidente sancao ler cartar receber dia berenice piana coordenador movimentar exmo senador paulo paim sta cartar diferente muito escrever autismo brasii divulgar falar referir tanto cartar enviar relatar situacao autista brasil ausencia politicar publicar pessoa nao continuar querer destinar historiar terminar mesmo pessoa comecou ser dizer coordenador excelencia tres ano lembrar detalhar palavra faco historico tao feliz instituir politicar nacional protecao direito pessoa transtornar espectro autista aprovar finalmente plenario senado federar titulo merecido comemoracao merecer comemoracao estar fazer brasil dia pedir predios ser iluminar luzir azul agostar assistir senado esperanca sentir vontade politicar algum senador discursar convencer poder apresentar projeto casar surgir entao tela excelencia senador paim falar cezar pássaro cantor nativista partir trotezito querenciar eterno palavra pradaria ceu ficar comovido homenagem perceber adiantar falir guri calcar curto comecou vidar fazer cursar senac ajudar feirar livrar portar alegrar alguem nao renegar origem mantar fiel raizes olhar franco direto decidir entao procurar tentativo convencer parlamentar parlamentar brasileiro olhar causar causar filho autismo situacao autista tratamento partir coracao dia conhecer caso dor extremo caso agravar precisar urgente brasil inteirar surpreso obter respostar imediato propor audiencia publicar colocar disposicao assessorar assessoria senado gabinete comissao orientacao nao entender importancia audiencias publicar palavra jamais esquecer sr berenice voces ir possivel voce dizer autista palavra lindo ouvir selar destinar autista brasileiro dia novembro relatar descrever acompanhar passar passar acontecer entao audiencia publicar senado federal comissao direito humano legislacao participativo conhecer companheiro ulisses costa baptista pai rafael autista vir lutar juntar comigo daqui frente audiencia pai incrivel ter historiar lutar rir janeiro unir forcar acabar mobilizar brasil prol causar causar audiencia historica vir muito brasil varios estar municipios saimos promessa levar adiantar projeto lei federal sonhar sonhar imediatamente reunir companheiro comecamos escrever lei casar itaborai rir janeiro variar reunioes feito projeto ser pensar aperfeicoado passar passar amplo assessoria senado perder contar quanto ligar gabinete senhor senador pedir orientacao tratar respeitar cordialidade lisura paciencia amizade excelencia senador citar nome excelencia tambem funcionarios senado marcar partir brasilia sonhar tornar realidade protocolar dia sentir util cidada brasileiro exercer direito vivo nao passagem mundo recordar esperanca temor lembrar muito ficar surdo tentar desanimar dizer promessa politicar nao acreditar chegariamos estar projeto comecou tramitar votacao cdh dar exatamente dia falecimento saudoso jose alencar viçar presidente republicar tambem apoiar autista caro senador memoriar palavra ficarao registrar historiar lei lembrar nao haver quorum senador estar funeral querer viçar presidente temiamos adiamento vesperas dia abril dia mundial conscientizacao autismo excelencia falar presidencia comissao daqui nao sair homenagear viçar presidente jose alencar ser velar hoje rir janeiro permanecer atar ultimar senador apareca votar preparar passar noite precisar daqui nao sair atar comparecam votar familias pessoa autismo merecer respeitar nao esperar haver senador voltar despois velorio vir votar senador mozarildo dar lembrar senador palavra comover atar lagrimas fazer crer acreditar acontecer chegar senador voltar minar estar missao nobre votacao acontecer vitoriar semana seguinte passar cas seguir plenario cobrir esperanca lembrar relatorio senador ana rita tambem agradecer seguir entao camara deputar precisar esforco redobrar atraves mail mobilizacao telefonema viagem vencer passar passar etapa etapa comissao comissao atar chegar maos deputar mara gabrilli sofrer pequeno alteracao sintonia parabens deputar mara movimentar ganhar brasil movimentar comecou pessoa agigantar atraves facebook mail palestrar conferenciar caminhar entrevisto audiencias publicar rede social naturalmente fernando cotta movimentar orgulhar autista brasilia aliar vinhamos trabalhar comecou cuidar zelar projeto ir lugar muito casar ulisses nao podiamos percorrer gabinete argumentar importancia nao retardar votacao nao alterar atender rapidez familias tao carente tratamento adequar companheiro permanecer juntar garr determinacao fibra atar corajoso jamais esmorecer jamais desanimar enfim projeto aprovar camara comissoes amplo mobilizacao deputar hugo leal deputar mara gabrilli rosa adefal voltar braco origem senado federal cdh comecou sentir vontade estavamos casar casar nao estranho imediatamente surgir senador lindbergh fazer assumir relatoria dar parecer favoravel abrancando conosco fazer causar justo belo aprovar cas unanimidade emendar seguir comissao cdh senador wellington dia pego relatoria coracoes ansioso articular executivo nao vetar senador aprovar unanimidade emendar seguir plenario maos abencoadas caro senador paim nascer juntar conosco projeto beneficiar milhoes familias milhoes coracoes projeto percalcos historiar lindo historiar tornar lei pôr berenice piana piana alar companheiro ulisses fernando cotta tanto herois anonimos pai estar ver brasil conhecer autismo falar autismo brasil inesquecivel audiencia publicar originar atitude senador inspirar atitude caro senador itaborai rir janeiro cidade brasileiro iei especificar autista lei berenice piana homenagem receber camara vereador inspirar audiencia publicar dia cdh senado presidencia presenca voltar redondo rir janeiro sancionar seguir quase dia tambem inspirar trabalhar senado pontar grosso parana cidade rir bonito rir janeiro fraiburgo santo catarino semear dar frutar estar olhendo trabalhar gente plantar estar ver flor trigar amarelar campo crescer fruto nao parir nascer respeitar senador prestar figurar senado hoje homenagem sincero nome milhoes brasileiro nao cansar festejar cantar chorar vitoriar congresso nacional tornar lei acordar sentir homem justar decidir semelhante acreditar nisso conduzir intentar honestidade firmeza garro determinacao homem vencer homem vencedor mensagem deixar homem mulher levar vencer seguir seguir causar homem excelencia tanto fazer cruzar conosco orgulhar chamar amigar contato lutar ideal dedicar vidar autista brasileiro dedicar restar dela deus der vidar saude completar frase caro senador extrair nao conheco hino riograndense paixao hino rir senador servir facanhas terra historiar lei abracos fraterno berenice piana piana mae dayan ano autista berenice piana piana lei muito cidade dar nome berenice piana piana tera simbologia lutar tambem lei federal nome berenice piana piana voce assistir mim tribuna amigo voce merecer autista merecer terminar claro emocao conter senador mozarildo presidir sessao olhar pensar nao chorar entao descontracao querido berenice lei chamar berenice piana piana\n",
            "Summary:  _START_ destaque a aprovacao senado federal projeto protege direitos pessoa transtorno espectro autista e assuntos _END_\n",
            "\n",
            "\n",
            "Speech:  sr angela portela bloco pronunciar seguinte discursar revisao orador senhor presidente senhor senador sr senador manifestacoes ultimar semana ocorrer pai traduzir natural desejar participacao jovem brasileiro extremo importancia extremo relevancia senado federal participacao importante considerar hoje reuniao presidente senado renan calheiros liderancas governar oposicao tambem estao preocupar inserir pautar congresso nacional reivindicacoes apontar populacao nessas manifestacoes assolar brasil inteirar senhor presidente dever ouvir voz ruir dever conduzir dialogar trocar experiencias mudancas proposto populacao nessas manifestacoes brasil partir nascer compreensao justo aspiracoes brasileiro crescer ano governar partir trabalhador presidente lula presidente dilma rousseff realizar movimentar inclusao social viver brasil espaco milhoes brasileiro passar integrar classe medir hoje representar populacao atual governar milhoes brasileiro deixar pobreza extremo gracas seriar iniciativo dentre citar brasil miseria programar extremo importancia mostrar vontade intenso presidente dilma acabar miseria pai prever constatar exito notavel processar inclusao demandar surgir previsivel cobranca servicos publicos qualidade justamente estrato social incorporar classe medir previsivel tambem ansiar participacao processar decisorio dimensao manifestacoes ruir surpreender nao aspiracoes dela participar constituir decorrencia processar historico viver origem politicar inclusao social principal bandeiro partir gostar observar proposito tambem roraima manifestacoes ganhar ruir cobrar seriar medir relevante populacao manifestante reclamar manha hoje afastamento governador anchieta roraima representativo dirigir assembleia legislativo pedir deputar estadual impeachment governador sessao entao parar nao prosseguir atar ambito roraima respostar dar manifestacao reivindicacoes apontar numerar elevar pessoa tambem querer participar protestar nacional melhoria condicoes vidar melhorar transporte coletivos educacao melhor qualidade enfim pautar conhecimento senador senador posturar ver roraima posicionamento autoridade governante diferente adotada governar presidente dilma presidente dilma rousseff compreender extensao importancia movimentar popular pronunciamento semana passar redar nacional radiar nao advertir impossibilidade conviver vandalismo violencia formular seriar proposto coadunar historico destacar abertura dialogar presidente chamar converso diretas representante movimento participar manifestacoes ruir sentar dialogar manter diverso encontro disposto ouvir reivindicacoes popular reunir governador unidade federacao alar prefeito principal cidade pai formular pacto pacto constar verdadeiro reformar institucional destinar aproximar nacao verdadeiro movimentar renovacao politicar institucional partir plebiscitar autorizar convocacao assembleia constituinte especificar plebiscitar central pacto proposto presidente classe politicar respostar brasileiro clamar mudancas social presidente brasil madurar avancar deixar claro nao ficar parar avancar progredir seguir frente reformar politicar dever ampliar participacao popular cidadania saber combater corrupcao constituir bandeiro historica partir propria presidente dilma historiar continuar fazer lutar corrupcao constar tambem proposto presidente tipificar corrupcao crime hediondo justar dinheiro publicar desviar senhor presidente significar dinheiro educacao abrir portar futurar criancas significar dinheiro tambem saude representar dor morte populacao presidente enfrentamento corrupcao contundente iniciativo fundamental criar legislacao classificar corrupcao doloso equivalente crime hediondo tambem incluir pacto avanco area saude dilma governador acelerar investimento contratar hospital unidade pronto atendimento unidade basicas saude sentir nao haver disponibilidade medicos brasileiro presidente desejar contratar profissional estrangeiro trabalhar exclusividade unico saude desejar destacar dizer presidente nao tratar medir hostil desrespeitoso profissional tratar acao emergencial localizar ter visto dificuldade estar enfrentar encontrar medicos numerar suficiente disposicao trabalhar areas remoto pai bandeiro inicial manifestacoes marcar pai saltar qualidade transportar publicar tambem essencial pacto propor presidente governar federal dever destinar milhoes investimento obrar mobilidade urbano pretender avancar rapido direcao transportar publicar qualidade acessivel alar sera ampliar desoneracao pi cofins diesel auxiliar controlo tarifar reuniao governador prefeito presidente dilma destacar precisar cuidar melhor educacao reconhecer reconhecer ampliacao acesso educacao valorizacao profissional exigir recurso sentir lembrar proposto partir soer campainha sr angela portela bloco concluir senhor presidente sentir lembrar proposto partir dela propria royalties petroleo recurso pre sal ser investir educacao projeto tramitar legislativo urgencia constitucional caber parlamentar aprovar espaco possivel senhor presidente inspirador constatar populacao brasileiro ruir diversificar agendar reivindicacoes dever tambem reconhecer atender reivindicacoes populacao constituir desafiar dever altura dele senhor presidente\n",
            "Summary:  _START_ satisfacao a postura governo federal frente manifestacoes populares _END_\n",
            "\n",
            "\n",
            "Speech:  senhor jayme campo bloco minoria dem pronunciar seguinte discursar revisao orador senhor presidente sr senhor senador manha hoje redar record televisao veicular importantissima reportagem violencia domesticar denunciar tragica situacao viver hoje milhar mulher brasileiro refens submissao imposto dependencia financeiro seguir vitimar calar sofrer sortir agressoes violencias contar lei maria penha diplomar potencialmente eficaz punicao agressor muito dessar mulher continuar amarrar grilhoes sofrimento nao ter autonomia financeiro capacitacao profissional lhe permitir custear sustentar algozar vir oferecer efetiva garantir protecao numerar mulher agredir imperioso instituir politicar publicar libertar riscar desamparar economico abril apresentar casar pls criar fundir nacional amparar mulher agredir destinar financiar ajudar pecuniaria treinamento profissional mulher razao violencia domesticar separar conjuges companheiro ajudar pecuniaria previsto dever pago durante consecutivo treinamento objetivo facilitar recolocacao mulher mercar trabalhar indicar fonte custear ocorrer senhor presidente promissor projeto autoria encontrar literalmente parar camara deputar ano senado discutir comissoes aprovar terminativamente camara receber autografar comeco ano passar permanecer atar hoje silente horar mulher assassinar brasil dar ministerio justica ano servico central atendimento mulher receber denunciar violencia deputar erika kokay distrito federal nomear relator comissao seguridade social familia displicentemente esquecido preparar apresentar relatorio colegiado materia poder seguir tramitacao reportagem referir sr senhor senador levar manha hoje procurar ilustrar relator infeliz explicacao deputar basear suposto tentativo aprimorar projeto melhor intencoes tardio sentir aperfeicoar proposicao saber alteracoes eventualmente aprovar camara farao materia retornar casar origem ser senado federal significar protelar aprovacao faco apelar senso faco nome caro capiberibe urgencia solucionar atual quadrar espancamento assassinato mulher agravar perverso esperar presidente republicar sancionar proposto camara concluir tramitacao senhor presidente chefe executivo qualidade mulher estadista nao furtar dever propiciar mulher brasileiro importante instrumentar protecao nao ser autoria projeto vontade politicar havera sobrepor interesse vaidade contabilidade partidaria insistir monopolizar criacao programar acoes social ficar registrar apelar indignacao esperanca ir viabilizar rapidamente fundir nacional amparar mulher agredir sociedade ganhar emancipacao ganhar mulher ganhar governar ganhar nacao democratico direito nesses tempo tanto desmando rogar deus imperio lei ordem poder conduzir brasil justar solidario ter sr presidente sr senhor senador\n",
            "Summary:  _START_ apelo sentido aprovacao camara deputados projeto autoria excelencia cria o fundo nacional amparo a mulheres agredidas _END_\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFjozuJUOI-T"
      },
      "source": [
        "## Análise dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "QYFldZXHN4m1",
        "outputId": "170bb2b5-309c-4b83-fea0-4890db494ba9"
      },
      "source": [
        "data_df['speech_word_freq'] = data_df['speech_clean'].apply(lambda x : len(x.split()))\n",
        "data_df['summary_word_freq'] = data_df['speech_summary_clean'].apply(lambda x : len(x.split()))\n",
        "data_df[['speech_word_freq', 'summary_word_freq']].hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f00cfcaf438>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f00cfc2f710>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40LOajGl9Qw0",
        "outputId": "73231527-5202-48d5-b1ec-5b332c66c572"
      },
      "source": [
        "print(f\"Stats of words in speech: \\n{data_df['speech_word_freq'].describe()}\")\n",
        "print(f\"Stats of words in  summary: \\n{data_df['summary_word_freq'].describe()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stats of words in speech: \n",
            "count    74167.000000\n",
            "mean       766.029488\n",
            "std        690.937547\n",
            "min          2.000000\n",
            "25%        311.000000\n",
            "50%        613.000000\n",
            "75%       1043.000000\n",
            "max      18209.000000\n",
            "Name: speech_word_freq, dtype: float64\n",
            "Stats of words in  summary: \n",
            "count    74167.000000\n",
            "mean        17.330443\n",
            "std          9.893072\n",
            "min          2.000000\n",
            "25%         11.000000\n",
            "50%         15.000000\n",
            "75%         21.000000\n",
            "max        225.000000\n",
            "Name: summary_word_freq, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBUOVTw9RAzQ",
        "outputId": "28f08448-77df-4f0c-e0e2-d11a99fef587"
      },
      "source": [
        "corpus_array = [doc.split() for doc in data_df['speech_clean']]\n",
        "corpus_summ = [doc.split() for doc in data_df['speech_summary_clean']]\n",
        "corpus_array.extend(corpus_summ)\n",
        "\n",
        "word_frequency = defaultdict(int)\n",
        "for sentence in corpus_array:\n",
        "    for word in sentence:\n",
        "        word_frequency[word] += 1\n",
        "print(f\"Vocabulary present in corpus: {len(word_frequency)}\")\n",
        "print(\"Most frequent words in corpus:\")\n",
        "sorted(word_frequency, key=word_frequency.get, reverse=True)[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary present in corpus: 151435\n",
            "Most frequent words in corpus:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nao',\n",
              " 'senhor',\n",
              " 'senador',\n",
              " 'presidente',\n",
              " 'excelencia',\n",
              " 'ser',\n",
              " 'governar',\n",
              " 'brasil',\n",
              " 'ano',\n",
              " 'brasileiro',\n",
              " 'pai',\n",
              " 'tambem',\n",
              " 'sao',\n",
              " 'estar',\n",
              " 'ter']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sslh0kK9VlN",
        "outputId": "b89ba41e-231f-42f7-8032-33b7dbfee404"
      },
      "source": [
        "first_percetile = data_df['speech_word_freq'].quantile(0.01)\n",
        "last_percetile = data_df['speech_word_freq'].quantile(0.99)\n",
        "data_df = data_df[(data_df['speech_word_freq'] > first_percetile)] \n",
        "data_df = data_df[(data_df['speech_word_freq'] < last_percetile)]\n",
        "\n",
        "print(f\"Removing outliers out less than {first_percetile} words and more than {last_percetile} words\")\n",
        "print(f\"Dataset size: {data_df.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing outliers out less than 47.0 words and more than 3035.6999999999825 words\n",
            "Dataset size: (72651, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mySMh9saVIFn",
        "outputId": "d9d2bf38-c659-4b17-8d6b-200b9bd69945"
      },
      "source": [
        "print(f\"Stats of words in speech: \\n{data_df['speech_word_freq'].describe()}\")\n",
        "print(f\"Stats of words in  summary: \\n{data_df['summary_word_freq'].describe()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stats of words in speech: \n",
            "count    72651.000000\n",
            "mean       736.796548\n",
            "std        550.214854\n",
            "min         48.000000\n",
            "25%        318.000000\n",
            "50%        613.000000\n",
            "75%       1033.000000\n",
            "max       3034.000000\n",
            "Name: speech_word_freq, dtype: float64\n",
            "Stats of words in  summary: \n",
            "count    72651.000000\n",
            "mean        17.340546\n",
            "std          9.843429\n",
            "min          2.000000\n",
            "25%         11.000000\n",
            "50%         15.000000\n",
            "75%         21.000000\n",
            "max        225.000000\n",
            "Name: summary_word_freq, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQozc-jRvtq"
      },
      "source": [
        "Salvando textos de discurso e resumos limpos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HJtnDPRX7R"
      },
      "source": [
        "data_df.to_csv('/content/drive/My Drive/Colab Notebooks/discursos_clean.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqLfHCJtSOUw"
      },
      "source": [
        "## Construção do Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1x3honRSBs0",
        "outputId": "92ea8aed-eb51-4cfa-8868-c56489ab984c"
      },
      "source": [
        "data_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/discursos_clean.csv')\n",
        "data_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 72651 entries, 0 to 72650\n",
            "Data columns (total 6 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   speech                72651 non-null  object\n",
            " 1   speech_summary        72651 non-null  object\n",
            " 2   speech_clean          72651 non-null  object\n",
            " 3   speech_summary_clean  72651 non-null  object\n",
            " 4   speech_word_freq      72651 non-null  int64 \n",
            " 5   summary_word_freq     72651 non-null  int64 \n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 3.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oposqBQ7We3G",
        "outputId": "0fffbaee-6d9e-4a55-b119-42535f60e7bf"
      },
      "source": [
        "corpus_array = [doc.split() for doc in data_df['speech_clean']]\n",
        "corpus_summ = [doc.split() for doc in data_df['speech_summary_clean']]\n",
        "corpus_array.extend(corpus_summ)\n",
        "print(f\"Size of corpus of all text: {len(corpus_array)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of corpus of all text: 145302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzUzX3XOSv6h",
        "outputId": "0e806810-ba6d-466f-f57b-7f8e459d3057"
      },
      "source": [
        "w2v_model = Word2Vec(\n",
        "    min_count=10\n",
        "    , window=15\n",
        "    , size=100\n",
        "    , workers=4\n",
        "    , compute_loss=True\n",
        ")\n",
        "\n",
        "t = time.time()\n",
        "w2v_model.build_vocab(\n",
        "    corpus_array\n",
        "    , progress_per=10000)\n",
        "print('Time to build vocab: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
        "\n",
        "t = time.time()\n",
        "w2v_model.train(\n",
        "    corpus_array\n",
        "    , total_examples=w2v_model.corpus_count\n",
        "    , epochs=15\n",
        "    , report_delay=1)\n",
        "print('Time to train the model: {} mins'.format(round((time.time() - t) / 60, 2)))\n",
        "\n",
        "print(f\"Size of corpus: {w2v_model.corpus_count}\")\n",
        "print(f\"Number of words in vocabulary: {len(w2v_model.wv.vectors)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.3 mins\n",
            "Time to train the model: 20.88 mins\n",
            "Size of corpus: 145302\n",
            "Number of words in vocabulary: 42847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_94iK3KyS1M6",
        "outputId": "9697b7dc-6fa9-4458-c086-13a63da006b3"
      },
      "source": [
        "w2v_model.wv.most_similar('pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('partido', 0.6495768427848816),\n",
              " ('democratas', 0.6384907960891724),\n",
              " ('petistas', 0.5904338359832764),\n",
              " ('tesoureiro', 0.5891529321670532),\n",
              " ('partir', 0.5829651355743408),\n",
              " ('teria', 0.555338442325592),\n",
              " ('candidata', 0.5511517524719238),\n",
              " ('tucana', 0.5367202758789062),\n",
              " ('pefelistas', 0.5365556478500366),\n",
              " ('oposicao', 0.5362462401390076)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHuE1_aMTSQQ"
      },
      "source": [
        "Salvando o modelo Word2Vec treinado para a base de discursos e resumos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydD-60vQS0nE"
      },
      "source": [
        "w2v_model.init_sims(replace=True)\n",
        "w2v_model.save(fname_or_handle = \"word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V_T4a2NUGhC"
      },
      "source": [
        "## Fase de treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhlfbCiUTKE"
      },
      "source": [
        "w2v_model = Word2Vec.load(\"word2vec.model\")\n",
        "data_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/discursos_clean.csv')\n",
        "data_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5-MVECkS0bB"
      },
      "source": [
        "word_index = speech_tokenizer.word_index\n",
        "\n",
        "embedding_matrix = np.zeros((x_voc_size, 100))\n",
        "oov_count = 0\n",
        "for word, i in word_index.items():\n",
        "    try:\n",
        "        embedding_matrix[i] = w2v_model.wv.word_vec(word)\n",
        "    except Exception as e:\n",
        "        oov_count += 1\n",
        "        print(e)\n",
        "print(f\"Out of Vocabulary count: {oov_count}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpvxwx9yWr18"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data_df['speech_clean']\n",
        "    , data_df['speech_summary_clean']\n",
        "    , test_size=0.2\n",
        "    , random_state=42\n",
        "    , shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i7xI4nHYY8h",
        "outputId": "b2e10a70-4fe2-4c82-8a52-e7f446a4784b"
      },
      "source": [
        "speech_tokenizer = Tokenizer()\n",
        "speech_tokenizer.fit_on_texts(list(x_train))\n",
        "speech_max_len = 610\n",
        "\n",
        "x_train = speech_tokenizer.texts_to_sequences(x_train)\n",
        "x_train = pad_sequences(x_train,  maxlen=speech_max_len, padding='post')\n",
        "\n",
        "x_test = speech_tokenizer.texts_to_sequences(x_test)\n",
        "x_test = pad_sequences(x_test, maxlen=speech_max_len, padding='post')\n",
        "\n",
        "x_voc_size = len(speech_tokenizer.word_index) + 1\n",
        "print(f\"Size of speeches vocabulary size: {x_voc_size}\")\n",
        "print(f\"Shape of train vector: {x_train.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "122983\n",
            "(58140, 610)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8rJHZlvYe5L",
        "outputId": "de2c0692-d66b-4311-8e7d-ca7fd7f5ef1c"
      },
      "source": [
        "summary_tokenizer = Tokenizer()\n",
        "summary_tokenizer.fit_on_texts(list(y_train))\n",
        "summary_max_len = 15\n",
        "\n",
        "y_train = summary_tokenizer.texts_to_sequences(y_train)\n",
        "y_train = pad_sequences(y_train, maxlen=summary_max_len, padding='post')\n",
        "\n",
        "y_test = summary_tokenizer.texts_to_sequences(y_test)\n",
        "y_test = pad_sequences(y_test, maxlen=summary_max_len, padding='post')\n",
        "\n",
        "y_voc_size = len(summary_tokenizer.word_index) + 1\n",
        "print(f\"Size of summary vocabulary size: {y_voc_size}\")\n",
        "print(f\"Shape of target train vector: {y_train.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30044\n",
            "(58140, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqCQZYebX5hE"
      },
      "source": [
        "Implementação do Bahdanau Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0He_KsEpgIdS"
      },
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO8n2GUbgN8Q",
        "outputId": "c6416cae-5e97-4a3f-bba1-ed6946131f85"
      },
      "source": [
        "K.clear_session()\n",
        "latent_dim = 200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(speech_max_len,))\n",
        "\n",
        "encoder_emb_layer = Embedding(x_voc_size, 100, weights=[embedding_matrix],input_length=speech_max_len, trainable=False)\n",
        "encoder_emb = encoder_emb_layer(encoder_inputs)\n",
        "\n",
        "encoder_bilstm=Bidirectional(\n",
        "    LSTM(latent_dim\n",
        "         , return_state=True\n",
        "         , return_sequences=True\n",
        "         , activation=\"tanh\"\n",
        "         , recurrent_activation=\"sigmoid\"\n",
        "         , recurrent_dropout=0\n",
        "         , unroll=False\n",
        "         , use_bias=True\n",
        "))\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_emb)\n",
        "state_h = Add()([forward_h, backward_h])\n",
        "state_c = Add()([forward_c, backward_c])\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "decoder_emb_layer = Embedding(x_voc_size, 100, weights=[embedding_matrix],input_length=summary_max_len, trainable=False)\n",
        "decoder_emb = decoder_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(decoder_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
        "\n",
        "# Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "# Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 610)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 610, 100)     12298300    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 610, 400), ( 481600      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    12298300    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 200)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 200)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 200),  240800      embedding_1[0][0]                \n",
            "                                                                 add[0][0]                        \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 400),  240400      bidirectional[0][0]              \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 600)    0           lstm_1[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 30044)  18056444    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 43,615,844\n",
            "Trainable params: 19,019,244\n",
            "Non-trainable params: 24,596,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ5-J0Ndga0q",
        "outputId": "7cc3a689-7b3f-4f4e-b314-46379e91aa9a"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "history=model.fit(\n",
        "    x=[x_train, y_train[:,:-1]]\n",
        "    , y=y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:]\n",
        "    , epochs=15\n",
        "    , callbacks=[es]\n",
        "    , batch_size=256\n",
        "    , verbose=1\n",
        "    , validation_data=(\n",
        "        [x_test, y_test[:,:-1]]\n",
        "        , y_test.reshape(y_test.shape[0],y_test.shape[1], 1)[:,1:])\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "228/228 [==============================] - 396s 2s/step - loss: 5.9200 - accuracy: 0.2321 - val_loss: 5.5203 - val_accuracy: 0.2663\n",
            "Epoch 2/15\n",
            "228/228 [==============================] - 405s 2s/step - loss: 5.3377 - accuracy: 0.2840 - val_loss: 5.1255 - val_accuracy: 0.2948\n",
            "Epoch 3/15\n",
            "228/228 [==============================] - 406s 2s/step - loss: 4.9981 - accuracy: 0.3064 - val_loss: 4.8847 - val_accuracy: 0.3138\n",
            "Epoch 4/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 4.7541 - accuracy: 0.3256 - val_loss: 4.6751 - val_accuracy: 0.3326\n",
            "Epoch 5/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 4.5582 - accuracy: 0.3411 - val_loss: 4.5594 - val_accuracy: 0.3416\n",
            "Epoch 6/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 4.4040 - accuracy: 0.3535 - val_loss: 4.4453 - val_accuracy: 0.3535\n",
            "Epoch 7/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 4.2674 - accuracy: 0.3643 - val_loss: 4.3504 - val_accuracy: 0.3641\n",
            "Epoch 8/15\n",
            "228/228 [==============================] - 408s 2s/step - loss: 4.1520 - accuracy: 0.3739 - val_loss: 4.2766 - val_accuracy: 0.3699\n",
            "Epoch 9/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 4.0517 - accuracy: 0.3823 - val_loss: 4.2295 - val_accuracy: 0.3757\n",
            "Epoch 10/15\n",
            "228/228 [==============================] - 408s 2s/step - loss: 3.9642 - accuracy: 0.3894 - val_loss: 4.1670 - val_accuracy: 0.3828\n",
            "Epoch 11/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 3.8810 - accuracy: 0.3966 - val_loss: 4.1419 - val_accuracy: 0.3861\n",
            "Epoch 12/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 3.8073 - accuracy: 0.4030 - val_loss: 4.1191 - val_accuracy: 0.3888\n",
            "Epoch 13/15\n",
            "228/228 [==============================] - 408s 2s/step - loss: 3.7396 - accuracy: 0.4089 - val_loss: 4.0758 - val_accuracy: 0.3934\n",
            "Epoch 14/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 3.6754 - accuracy: 0.4141 - val_loss: 4.0372 - val_accuracy: 0.3976\n",
            "Epoch 15/15\n",
            "228/228 [==============================] - 407s 2s/step - loss: 3.6152 - accuracy: 0.4193 - val_loss: 4.0227 - val_accuracy: 0.4001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "FnVTE0zagcvo",
        "outputId": "0168f55f-1938-460f-b90f-001e4faec181"
      },
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPLDzQzQYWsy"
      },
      "source": [
        "## Fase de Inferência do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeordbFMgkd1"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(speech_max_len,400))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2 = decoder_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRIwnzv7gk-Z"
      },
      "source": [
        "reverse_source_word_index=speech_tokenizer.index_word\n",
        "reverse_target_word_index=summary_tokenizer.index_word\n",
        "target_word_index=summary_tokenizer.word_index\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    # print('input_seq: {}, e_out: {} '.format(input_seq,e_out))\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        if sampled_token_index == 0:\n",
        "            sampled_token = 'end'\n",
        "        else:\n",
        "            sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        # print(\"sampled_token:\",sampled_token)\n",
        "        if(sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
        "                stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        # stop_condition = True\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_2d3p1hjSGN"
      },
      "source": [
        "for i in range(10,20):\n",
        "    print(f\"Review: {seq2text(x_test[i])}\")\n",
        "    summ = seq2summary(y_test[i])\n",
        "    print(f\"Original summary: {summ}\")\n",
        "    pred_summ = decode_sequence(x_test[i].reshape(1,  speech_max_len))\n",
        "    print(f\"Predicted summary: {pred_summ}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B5FL4rMZXQK"
      },
      "source": [
        "## Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJC3OF_V6_bU"
      },
      "source": [
        "rouge = Rouge()\n",
        "\n",
        "data = []\n",
        "for i in range(len(x_test)):\n",
        "    summ = seq2summary(y_test[i])\n",
        "    pred_summ = decode_sequence(x_test[i].reshape(1,speech_max_len))\n",
        "    rouge_list = [0, 0, 0]\n",
        "    if len(pred_summ) > 0 and len(summ):\n",
        "        scores = rouge.get_scores(pred_summ, summ)[0]\n",
        "        rouge_list = [scores['rouge-1']['f'], scores['rouge-2']['f'], scores['rouge-l']['f']]\n",
        "    data.append([\n",
        "        seq2text(x_test[i])\n",
        "        , summ\n",
        "        , pred_summ\n",
        "        , rouge_list[0]\n",
        "        , rouge_list[1]\n",
        "        , rouge_list[2]\n",
        "    ])\n",
        "\n",
        "val_df = pd.DataFrame(data, columns=['speech', 'original_summary', 'predicted_summary', 'rouge_1', 'rouge_2', 'rouge_l'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqqwA2PEpGeL",
        "outputId": "3a374bf6-da10-42d9-d3d2-29328f0176e7"
      },
      "source": [
        "print(f\"Rouge-1 average score: {val_df['rouge_1'].mean()}\")\n",
        "print(f\"Rouge-2 average score: {val_df['rouge_2'].mean()}\")\n",
        "print(f\"Rouge-L average score: {val_df['rouge_l'].mean()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rouge-1 average score: 0.17907017583738444\n",
            "Rouge-2 average score: 0.06125812653200354\n",
            "Rouge-L average score: 0.1756311384612113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk5RGNjqY4yp"
      },
      "source": [
        "_, _, F1 = score(val_data['predicted_summary'].tolist(), val_data['original_summary'].tolist(), lang=\"pt\", verbose=True)\n",
        "print(f\"System level F1 score: {F1.mean():.3f}\")\n",
        "val_data['bertscore'] = F1.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhH3fVLWqS5y"
      },
      "source": [
        "val_df.to_csv('/content/drive/My Drive/Colab Notebooks/resumos_teste.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}